{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tflite_runtime.interpreter as tflite\n",
    "\n",
    "def gstreamer_pipeline(sensor_id=0, sensor_mode=3, capture_width=1280, capture_height=720, display_width=640, display_height=480, framerate=30, flip_method=2):\n",
    "    return (\n",
    "        f'nvarguscamerasrc sensor-id={sensor_id} sensor-mode={sensor_mode} ! '\n",
    "        f'video/x-raw(memory:NVMM), width=(int){capture_width}, height=(int){capture_height}, '\n",
    "        f'format=(string)NV12, framerate=(fraction){framerate}/1 ! '\n",
    "        f'nvvidconv flip-method={flip_method} ! '\n",
    "        f'video/x-raw, width=(int){display_width}, height=(int){display_height}, format=(string)BGRx ! '\n",
    "        f'videoconvert ! '\n",
    "        f'video/x-raw, format=(string)BGR ! appsink'\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the TensorFlow Lite interpreter\n",
    "interpreter = tflite.Interpreter(model_path='your_model.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Define a function to preprocess the frame\n",
    "def preprocess_frame(frame):\n",
    "    # Adjust these preprocessing steps as per your model requirements\n",
    "    frame_resized = cv2.resize(frame, (input_details[0]['shape'][2], input_details[0]['shape'][1]))\n",
    "    frame_normalized = frame_resized / 255.0  # Normalize if your model expects this\n",
    "    return np.expand_dims(frame_normalized, axis=0).astype(np.float32)\n",
    "\n",
    "# Define a function for postprocessing\n",
    "def postprocess_frame(frame, output_data):\n",
    "    # Adjust this postprocessing as per your model's output format\n",
    "    for detection in output_data[0]:\n",
    "        # Draw detection boxes on the frame\n",
    "        pass\n",
    "\n",
    "# Initialize video capture with GStreamer pipeline (adjust this as needed)\n",
    "cap = cv2.VideoCapture('your_gstreamer_pipeline', cv2.CAP_GSTREAMER)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Preprocess the frame\n",
    "    input_data = preprocess_frame(frame)\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "    # Run inference\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Retrieve detection results\n",
    "    output_data = [interpreter.get_tensor(output_details[i]['index']) for i in range(len(output_details))]\n",
    "\n",
    "    # Postprocess and display the frame\n",
    "    postprocess_frame(frame, output_data)\n",
    "    cv2.imshow('Object Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
